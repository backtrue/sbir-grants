"""
SBIR Data MCP Server
å°ˆæ³¨æ–¼ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•å®˜æ–¹ API

åŠŸèƒ½ï¼š
1. ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•ç¸½é«”çµ±è¨ˆè³‡æ–™åº« API
2. å·¥ç ”é™¢ IEKã€è³‡ç­–æœƒ MIC ç”± Claude çš„ search_web è™•ç†
"""

from mcp.server import Server
from mcp.types import Tool, TextContent
import httpx
import json
from typing import Any, Optional
from datetime import datetime
from pydantic import BaseModel

# Import proposal generator functions
try:
    from mcp_server.proposal_generator_impl import (
        start_proposal_generator,
        save_answer,
        get_progress,
        generate_proposal,
        STATE_FILE
    )
except ImportError:
    # Fallback: functions will be defined later in this file
    pass

# ============================================
# è³‡æ–™æ¨¡å‹
# ============================================

class MOEAStatData(BaseModel):
    """ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•æ•¸æ“šæ ¼å¼"""
    category: str        # é¡åˆ¥
    period: str          # çµ±è¨ˆæœŸé–“
    value: float         # æ•¸å€¼
    unit: str            # å–®ä½
    source_url: str      # ä¾†æºç¶²å€

# ============================================
# MCP Server åˆå§‹åŒ–
# ============================================

app = Server("sbir-data-server")

# ============================================
# å·¥å…·å®šç¾©
# ============================================

@app.list_tools()
async def list_tools() -> list[Tool]:
    """å®šç¾©å¯ç”¨çš„å·¥å…·"""
    return [
        Tool(
            name="search_knowledge_base",
            description="æœå°‹ SBIR çŸ¥è­˜åº«ä¸­çš„ç›¸é—œæ–‡ä»¶ã€‚å¯æœå°‹æ–¹æ³•è«–ã€FAQã€æª¢æ ¸æ¸…å–®ã€æ¡ˆä¾‹ç­‰ã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœå°‹é—œéµå­—ï¼Œå¦‚ï¼šå‰µæ–°ã€å¸‚å ´åˆ†æã€ç¶“è²»ã€è³‡æ ¼ç­‰"
                    },
                    "category": {
                        "type": "string",
                        "description": "æ–‡ä»¶é¡åˆ¥ï¼ˆå¯é¸ï¼‰",
                        "enum": ["methodology", "faq", "checklist", "case_study", "template", "all"],
                        "default": "all"
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="read_document",
            description="è®€å– SBIR çŸ¥è­˜åº«ä¸­çš„ç‰¹å®šæ–‡ä»¶å…§å®¹",
            inputSchema={
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "æ–‡ä»¶çš„ç›¸å°è·¯å¾‘ï¼Œå¦‚ï¼šreferences/methodology_innovation.md"
                    }
                },
                "required": ["file_path"]
            }
        ),
        Tool(
            name="query_moea_statistics",
            description="æŸ¥è©¢ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•ç¸½é«”çµ±è¨ˆè³‡æ–™åº«ï¼ˆå®˜æ–¹ APIï¼‰ã€‚å¯æŸ¥è©¢ç”¢æ¥­ç”¢å€¼ã€å‡ºå£ã€å°±æ¥­ç­‰æ•¸æ“šã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "industry": {
                        "type": "string",
                        "description": "ç”¢æ¥­åˆ¥ï¼Œå¦‚ï¼šæ©Ÿæ¢°ã€åŒ–å·¥ã€é›»å­ã€è³‡é€šè¨Š"
                    },
                    "stat_type": {
                        "type": "string",
                        "description": "çµ±è¨ˆé¡å‹ï¼šç”¢å€¼ã€å‡ºå£ã€å°±æ¥­äººæ•¸",
                        "enum": ["ç”¢å€¼", "å‡ºå£", "å°±æ¥­äººæ•¸"]
                    },
                    "start_year": {
                        "type": "integer",
                        "description": "èµ·å§‹å¹´ä»½ï¼ˆè¥¿å…ƒå¹´ï¼‰",
                        "default": 2020
                    },
                    "end_year": {
                        "type": "integer",
                        "description": "çµæŸå¹´ä»½ï¼ˆè¥¿å…ƒå¹´ï¼‰",
                        "default": 2024
                    }
                },
                "required": ["industry", "stat_type"]
            }
        ),
        Tool(
            name="search_moea_website",
            description="æœå°‹ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•ç¶²ç«™ï¼ˆç•¶ API ç„¡æ³•æ»¿è¶³éœ€æ±‚æ™‚ä½¿ç”¨ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "keyword": {
                        "type": "string",
                        "description": "æœå°‹é—œéµå­—"
                    }
                },
                "required": ["keyword"]
            }
        ),
        Tool(
            name="start_proposal_generator",
            description="é–‹å§‹äº’å‹•å¼è¨ˆç•«æ›¸ç”Ÿæˆå™¨ï¼Œè¼‰å…¥å•é¡Œä¸¦åˆå§‹åŒ–ç‹€æ…‹",
            inputSchema={
                "type": "object",
                "properties": {
                    "phase": {
                        "type": "string",
                        "description": "è¨ˆç•«éšæ®µ",
                        "enum": ["phase1", "phase2"],
                        "default": "phase1"
                    }
                },
                "required": []
            }
        ),
        Tool(
            name="save_answer",
            description="ä¿å­˜å•ç­”ç­”æ¡ˆåˆ°ç‹€æ…‹æª”æ¡ˆ",
            inputSchema={
                "type": "object",
                "properties": {
                    "question_id": {
                        "type": "string",
                        "description": "å•é¡Œ ID"
                    },
                    "answer": {
                        "type": "string",
                        "description": "ç”¨æˆ¶çš„ç­”æ¡ˆ"
                    }
                },
                "required": ["question_id", "answer"]
            }
        ),
        Tool(
            name="get_progress",
            description="å–å¾—è¨ˆç•«æ›¸ç”Ÿæˆé€²åº¦",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="generate_proposal",
            description="æ ¹æ“šå·²å›ç­”çš„å•é¡Œç”Ÿæˆå®Œæ•´è¨ˆç•«æ›¸",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="update_knowledge_base",
            description="æ›´æ–° SBIR çŸ¥è­˜åº«åˆ°æœ€æ–°ç‰ˆæœ¬ï¼ˆå¾ GitHub æ‹‰å–æ›´æ–°ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="check_proposal",
            description="æª¢æ ¸ SBIR è¨ˆç•«æ›¸å®Œæ•´åº¦ã€‚é€™æ˜¯è‡ªæˆ‘æª¢æŸ¥å·¥å…·ï¼Œç”¨ä¾†ç¢ºèªè¨ˆç•«æ›¸æ˜¯å¦æ¶µè“‹æ‰€æœ‰å¿…è¦å…§å®¹ï¼Œéè©•å¯©çµæœé æ¸¬ã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "proposal_content": {
                        "type": "string",
                        "description": "è¨ˆç•«æ›¸å…§å®¹ï¼ˆå…¨æ–‡æˆ–ä¸»è¦ç« ç¯€ï¼‰"
                    },
                    "phase": {
                        "type": "string",
                        "description": "è¨ˆç•«éšæ®µ",
                        "enum": ["phase1", "phase2"],
                        "default": "phase1"
                    }
                },
                "required": ["proposal_content"]
            }
        ),
        Tool(
            name="calculate_budget",
            description="SBIR ç¶“è²»è©¦ç®—å·¥å…·ã€‚æ ¹æ“šè¨ˆç•«éšæ®µå’Œç¸½ç¶“è²»ï¼Œè‡ªå‹•å»ºè­°å„é …ç¶“è²»åˆ†é…æ¯”ä¾‹ã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "phase": {
                        "type": "string",
                        "description": "è¨ˆç•«éšæ®µ",
                        "enum": ["phase1", "phase2", "phase2plus"],
                        "default": "phase1"
                    },
                    "total_budget": {
                        "type": "number",
                        "description": "è¨ˆç•«ç¸½ç¶“è²»ï¼ˆè¬å…ƒï¼‰"
                    },
                    "project_type": {
                        "type": "string",
                        "description": "è¨ˆç•«é¡å‹",
                        "enum": ["æŠ€è¡“ç ”ç™¼", "è»Ÿé«”é–‹ç™¼", "ç¡¬é«”é–‹ç™¼", "æœå‹™å‰µæ–°"],
                        "default": "æŠ€è¡“ç ”ç™¼"
                    }
                },
                "required": ["total_budget"]
            }
        ),
        Tool(
            name="export_proposal_word",
            description="å°‡è¨ˆç•«æ›¸åŒ¯å‡ºç‚º Word æª”æ¡ˆï¼ˆ.docxï¼‰ã€‚æ”¯æ´å®Œæ•´æ ¼å¼ï¼Œå¯ç›´æ¥é€ä»¶ã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "content": {
                        "type": "string",
                        "description": "è¨ˆç•«æ›¸çš„ Markdown å…§å®¹"
                    },
                    "filename": {
                        "type": "string",
                        "description": "æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼‰",
                        "default": "SBIR_è¨ˆç•«æ›¸"
                    },
                    "company_name": {
                        "type": "string",
                        "description": "å…¬å¸åç¨±ï¼ˆç”¨æ–¼é é¦–ï¼‰"
                    },
                    "project_name": {
                        "type": "string",
                        "description": "è¨ˆç•«åç¨±ï¼ˆç”¨æ–¼æ¨™é¡Œé ï¼‰"
                    }
                },
                "required": ["content"]
            }
        )
    ]

# ============================================
# å·¥å…·åŸ·è¡Œ
# ============================================

@app.call_tool()
async def call_tool(name: str, arguments: Any) -> list[TextContent]:
    """åŸ·è¡Œå·¥å…·"""
    if name == "search_knowledge_base":
        return await search_knowledge_base(
            arguments["query"],
            arguments.get("category", "all")
        )
    elif name == "read_document":
        return await read_document(arguments["file_path"])
    elif name == "query_moea_statistics":
        return await query_moea_statistics(
            arguments["industry"],
            arguments["stat_type"],
            arguments.get("start_year", 2020),
            arguments.get("end_year", 2024)
        )
    elif name == "search_moea_website":
        return await search_moea_website(arguments["keyword"])
    elif name == "start_proposal_generator":
        return await start_proposal_generator(arguments.get("phase", "phase1"))
    elif name == "save_answer":
        return await save_answer(arguments["question_id"], arguments["answer"])
    elif name == "get_progress":
        return await get_progress()
    elif name == "generate_proposal":
        return await generate_proposal()
    elif name == "update_knowledge_base":
        return await update_knowledge_base()
    elif name == "check_proposal":
        return await check_proposal(
            arguments["proposal_content"],
            arguments.get("phase", "phase1")
        )
    elif name == "calculate_budget":
        return await calculate_budget(
            arguments["total_budget"],
            arguments.get("phase", "phase1"),
            arguments.get("project_type", "æŠ€è¡“ç ”ç™¼")
        )
    elif name == "export_proposal_word":
        return await export_proposal_word(
            arguments["content"],
            arguments.get("filename", "SBIR_è¨ˆç•«æ›¸"),
            arguments.get("company_name", ""),
            arguments.get("project_name", "")
        )
    else:
        raise ValueError(f"Unknown tool: {name}")

# ============================================
# æ ¸å¿ƒåŠŸèƒ½ï¼šçŸ¥è­˜åº«æœå°‹èˆ‡è®€å–
# ============================================

import os
import glob

# å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼ˆserver.py çš„ä¸Šä¸€å±¤ï¼‰
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ç‰ˆæœ¬æª¢æŸ¥ï¼ˆæ¯å¤©æœ€å¤šæª¢æŸ¥ä¸€æ¬¡ï¼‰
import time
import subprocess
LAST_VERSION_CHECK = 0
VERSION_CHECK_INTERVAL = 86400  # 24 å°æ™‚

def check_for_updates() -> str | None:
    """
    æª¢æŸ¥æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬å¯ç”¨
    è¿”å›æ›´æ–°æé†’è¨Šæ¯ï¼Œå¦‚æœå·²æ˜¯æœ€æ–°å‰‡è¿”å› None
    """
    global LAST_VERSION_CHECK
    
    current_time = time.time()
    
    # æ¯ 24 å°æ™‚åªæª¢æŸ¥ä¸€æ¬¡
    if current_time - LAST_VERSION_CHECK < VERSION_CHECK_INTERVAL:
        return None
    
    LAST_VERSION_CHECK = current_time
    
    try:
        # å–å¾—æœ¬åœ°æœ€æ–° commit
        local_result = subprocess.run(
            ["git", "rev-parse", "HEAD"],
            cwd=PROJECT_ROOT,
            capture_output=True,
            text=True,
            timeout=5
        )
        if local_result.returncode != 0:
            return None
        local_commit = local_result.stdout.strip()[:7]
        
        # å–å¾—é ç«¯æœ€æ–° commit
        subprocess.run(
            ["git", "fetch", "--quiet"],
            cwd=PROJECT_ROOT,
            capture_output=True,
            timeout=10
        )
        
        remote_result = subprocess.run(
            ["git", "rev-parse", "origin/main"],
            cwd=PROJECT_ROOT,
            capture_output=True,
            text=True,
            timeout=5
        )
        if remote_result.returncode != 0:
            return None
        remote_commit = remote_result.stdout.strip()[:7]
        
        # æ¯”è¼ƒç‰ˆæœ¬
        if local_commit != remote_commit:
            return f"\n\n---\nğŸ’¡ **æœ‰æ–°ç‰ˆæœ¬å¯ç”¨ï¼** æ‚¨çš„ç‰ˆæœ¬ï¼š`{local_commit}`ï¼Œæœ€æ–°ç‰ˆæœ¬ï¼š`{remote_commit}`\nè«‹èªªã€Œ**æ›´æ–°çŸ¥è­˜åº«**ã€ä¾†ç²å¾—æœ€æ–°å…§å®¹ã€‚"
        
        return None
        
    except Exception:
        # ä»»ä½•éŒ¯èª¤éƒ½éœé»˜å¿½ç•¥
        return None


async def search_knowledge_base(query: str, category: str = "all") -> list[TextContent]:
    """
    æ··åˆæœå°‹ï¼šé—œéµå­— + RAG èªæ„æœå°‹
    """
    
    # å®šç¾©æœå°‹ç›®éŒ„
    search_dirs = {
        "methodology": "references/methodology_*.md",
        "faq": "faq/*.md",
        "checklist": "checklists/*.md",
        "case_study": "examples/case_studies/*.md",
        "template": "templates/*.md",
        "all": "**/*.md"
    }
    
    pattern = search_dirs.get(category, "**/*.md")
    search_path = os.path.join(PROJECT_ROOT, pattern)
    
    # æœå°‹æª”æ¡ˆ
    files = glob.glob(search_path, recursive=True)
    
    # ===== 1. é—œéµå­—æœå°‹ =====
    keywords = [kw.strip().lower() for kw in query.split() if kw.strip()]
    keyword_results = {}  # path -> score
    
    for file_path in files:
        file_name = os.path.basename(file_path).lower()
        relative_path = os.path.relpath(file_path, PROJECT_ROOT)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().lower()
            
            score = 0
            matched_keywords = []
            
            for keyword in keywords:
                if keyword in file_name:
                    score += 3
                    matched_keywords.append(keyword)
                elif keyword in content:
                    count = min(content.count(keyword), 5)
                    score += count
                    matched_keywords.append(keyword)
            
            if score > 0:
                keyword_results[relative_path] = {
                    "path": relative_path,
                    "name": os.path.basename(file_path),
                    "category": get_category_from_path(relative_path),
                    "keyword_score": score,
                    "matched_keywords": len(set(matched_keywords)),
                    "total_keywords": len(keywords)
                }
        except Exception:
            continue
    
    # ===== 2. èªæ„æœå°‹ (RAG) =====
    semantic_results = {}  # path -> {similarity, content, metadata}
    semantic_available = False
    
    try:
        from vector_search import semantic_search, needs_reindex
        
        persist_dir = os.path.join(os.path.dirname(__file__), "chroma_db")
        
        if not needs_reindex(persist_dir):
            semantic_available = True
            results = semantic_search(query, persist_dir, n_results=15)
            
            for result in results:
                semantic_results[result["id"]] = {
                    "similarity": result["similarity"],
                    "content": result.get("content", ""),
                    "metadata": result.get("metadata", {})
                }
    except Exception as e:
        # èªæ„æœå°‹ä¸å¯ç”¨ï¼Œåƒ…ä½¿ç”¨é—œéµå­—æœå°‹
        pass

    
    # ===== 3. æ··åˆæ’åº =====
    KEYWORD_WEIGHT = 0.4
    SEMANTIC_WEIGHT = 0.6
    
    all_paths = set(keyword_results.keys()) | set(semantic_results.keys())
    
    # æ­£è¦åŒ–é—œéµå­—åˆ†æ•¸
    max_keyword_score = max([r["keyword_score"] for r in keyword_results.values()], default=1)
    
    final_scores = []
    for path in all_paths:
        # é—œéµå­—åˆ†æ•¸ï¼ˆæ­£è¦åŒ–åˆ° 0-1ï¼‰
        kw_info = keyword_results.get(path, {})
        kw_score = kw_info.get("keyword_score", 0) / max_keyword_score if max_keyword_score > 0 else 0
        
        # èªæ„åˆ†æ•¸ï¼ˆå·²ç¶“æ˜¯ 0-1ï¼‰
        sem_info = semantic_results.get(path, {})
        sem_score = sem_info.get("similarity", 0) if isinstance(sem_info, dict) else 0
        
        # åŠ æ¬Šç¸½åˆ†
        if semantic_available:
            final_score = kw_score * KEYWORD_WEIGHT + sem_score * SEMANTIC_WEIGHT
        else:
            final_score = kw_score  # åªæœ‰é—œéµå­—
        
        # å–å¾—æ–‡ä»¶è³‡è¨Š
        if path in keyword_results:
            info = keyword_results[path].copy()
        else:
            # å¾èªæ„çµæœå–å¾— metadata
            sem_metadata = sem_info.get("metadata", {}) if isinstance(sem_info, dict) else {}
            info = {
                "path": sem_metadata.get("file_path", path),
                "name": sem_metadata.get("file", os.path.basename(path)),
                "category": get_category_from_path(path),
                "matched_keywords": 0,
                "total_keywords": len(keywords)
            }
        
        info["final_score"] = final_score
        info["semantic_score"] = sem_score
        
        # å¾èªæ„çµæœå–å¾—å…§å®¹é è¦½
        if isinstance(sem_info, dict):
            content = sem_info.get("content", "")
            metadata = sem_info.get("metadata", {})
            
            if metadata.get("preview"):
                info["preview"] = metadata.get("preview")
            
            if content:
                # å–å‰ 100 å€‹å­—ç¬¦ä½œç‚ºå…§å®¹ç‰‡æ®µ
                info["content_snippet"] = content[:100].replace('\n', ' ').strip()
            
            # æå–ä¾†æºè³‡è¨Š
            if metadata.get("source_url"):
                info["source_url"] = metadata.get("source_url")
            if metadata.get("source_title"):
                info["source_title"] = metadata.get("source_title")
            if metadata.get("source_date"):
                info["source_date"] = metadata.get("source_date")
        
        final_scores.append(info)

    
    # æŒ‰ç¸½åˆ†æ’åº
    final_scores.sort(key=lambda x: x["final_score"], reverse=True)
    
    # ===== 4. æ ¼å¼åŒ–çµæœ =====
    if not final_scores:
        result = f"""
## æœå°‹çµæœ

æ‰¾ä¸åˆ°èˆ‡ã€Œ{query}ã€ç›¸é—œçš„æ–‡ä»¶ã€‚

**å»ºè­°**ï¼š
- è©¦è©¦å…¶ä»–é—œéµå­—
- æŸ¥çœ‹å®Œæ•´æ–‡ä»¶åˆ—è¡¨ï¼šREADME.md
"""
    else:
        search_mode = "ğŸ” æ··åˆæœå°‹ï¼ˆé—œéµå­— + AI èªæ„ï¼‰" if semantic_available else "ğŸ” é—œéµå­—æœå°‹"
        result = f"""
## æœå°‹çµæœï¼šæ‰¾åˆ° {len(final_scores)} å€‹ç›¸é—œæ®µè½

**æœå°‹æ¨¡å¼**ï¼š{search_mode}
**æœå°‹é—œéµå­—**ï¼š{query}

ğŸ’¡ **æç¤º**ï¼šä»¥ä¸‹çµæœåŒ…å«æ–‡ä»¶ä¾†æºå’Œå…§å®¹é è¦½ï¼ŒClaude æœƒè‡ªå‹•é–±è®€é€™äº›å…§å®¹ä¸¦ç‚ºæ‚¨ç¶œåˆç­”æ¡ˆã€‚

"""
        for i, file_info in enumerate(final_scores[:10], 1):
            # é¡¯ç¤ºåŒ¹é…åº¦
            if semantic_available and file_info.get("semantic_score", 0) > 0:
                relevance = f"ç›¸é—œåº¦: {file_info['final_score']*100:.0f}%"
            else:
                match_ratio = f"{file_info.get('matched_keywords', 0)}/{file_info['total_keywords']}"
                relevance = f"åŒ¹é…: {match_ratio} é—œéµå­—"
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ chunk é è¦½
            preview = file_info.get("preview", "")
            content_snippet = file_info.get("content_snippet", "")
            source_url = file_info.get("source_url")
            source_title = file_info.get("source_title")
            source_date = file_info.get("source_date")
            
            result += f"{i}. **{file_info['name']}** ({relevance})\n"
            
            if preview:
                result += f"   > ğŸ“„ {preview}\n"
            
            if content_snippet:
                result += f"   > ã€Œ{content_snippet}ã€\n"
            
            result += f"   - ğŸ“ é¡åˆ¥ï¼š{file_info['category']}\n"
            result += f"   - ğŸ“ ä½ç½®ï¼š`{file_info['path']}`\n"
            
            # é¡¯ç¤ºå®˜æ–¹ä¾†æº
            if source_url:
                result += f"   - ğŸ”— **å®˜æ–¹å‡ºè™•**ï¼š{source_url}\n"
            if source_title:
                result += f"   - ğŸ“‹ ä¾†æºæ¨™é¡Œï¼š{source_title}\n"
            if source_date:
                result += f"   - ğŸ“… ç™¼å¸ƒæ—¥æœŸï¼š{source_date}\n"
            
            result += f"   - ğŸ” ä½¿ç”¨ `read_document` å·¥å…·å¯è®€å–å®Œæ•´å…§å®¹\n\n"
        
        if len(final_scores) > 10:
            result += f"\nï¼ˆé‚„æœ‰ {len(final_scores) - 10} å€‹ç›¸é—œæ®µè½æœªé¡¯ç¤ºï¼‰\n"
        
        if not semantic_available:
            result += "\nğŸ’¡ **æç¤º**ï¼šåŸ·è¡Œ `python mcp-server/build_index.py` å¯å•Ÿç”¨ AI èªæ„æœå°‹ï¼Œæå‡æœå°‹æº–ç¢ºåº¦ã€‚\n"
        
        # åŠ å…¥å¼•ç”¨èªªæ˜
        result += "\n---\n\n"
        result += "ğŸ“Œ **å¦‚ä½•ä½¿ç”¨é€™äº›çµæœ**ï¼š\n"
        result += "- Claude æœƒè‡ªå‹•é–±è®€ä¸Šè¿°å…§å®¹ä¸¦ç‚ºæ‚¨ç¶œåˆç­”æ¡ˆ\n"
        result += "- ç­”æ¡ˆæœƒåŒ…å«å…·é«”çš„ä¾†æºå¼•ç”¨\n"
        result += "- å¦‚éœ€æŸ¥è­‰ï¼Œå¯ä½¿ç”¨ `read_document` å·¥å…·é–±è®€å®Œæ•´æ–‡ä»¶\n"

    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬
    update_notice = check_for_updates()
    if update_notice:
        result += update_notice
    
    return [TextContent(type="text", text=result)]


async def read_document(file_path: str) -> list[TextContent]:
    """
    è®€å–æŒ‡å®šçš„æ–‡ä»¶å…§å®¹
    """
    
    full_path = os.path.join(PROJECT_ROOT, file_path)
    
    # å®‰å…¨æª¢æŸ¥ï¼šç¢ºä¿è·¯å¾‘åœ¨å°ˆæ¡ˆç›®éŒ„å…§
    if not os.path.abspath(full_path).startswith(PROJECT_ROOT):
        return [TextContent(
            type="text",
            text=f"âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–å°ˆæ¡ˆç›®éŒ„å¤–çš„æª”æ¡ˆ"
        )]
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(full_path):
        return [TextContent(
            type="text",
            text=f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ `{file_path}`\n\nè«‹ä½¿ç”¨ `search_knowledge_base` å·¥å…·æœå°‹æ­£ç¢ºçš„æª”æ¡ˆè·¯å¾‘ã€‚"
        )]
    
    # è®€å–æª”æ¡ˆ
    try:
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        result = f"""
## ğŸ“„ {os.path.basename(file_path)}

**è·¯å¾‘**ï¼š`{file_path}`

---

{content}
"""
        return [TextContent(type="text", text=result)]
        
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"âŒ è®€å–æª”æ¡ˆå¤±æ•—ï¼š{str(e)}"
        )]

def get_category_from_path(path: str) -> str:
    """æ ¹æ“šè·¯å¾‘åˆ¤æ–·æ–‡ä»¶é¡åˆ¥"""
    if "methodology" in path:
        return "æ–¹æ³•è«–"
    elif "faq" in path:
        return "å¸¸è¦‹å•é¡Œ"
    elif "checklist" in path:
        return "æª¢æ ¸æ¸…å–®"
    elif "case_studies" in path:
        return "æ¡ˆä¾‹ç ”ç©¶"
    elif "template" in path:
        return "ç¯„æœ¬"
    elif "quick_start" in path:
        return "å¿«é€Ÿå•Ÿå‹•"
    else:
        return "å…¶ä»–"

# ============================================
# æ ¸å¿ƒåŠŸèƒ½ï¼šæŸ¥è©¢ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™• API
# ============================================

async def query_moea_statistics(
    industry: str,
    stat_type: str,
    start_year: int,
    end_year: int
) -> list[TextContent]:
    """
    æŸ¥è©¢ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•ç¸½é«”çµ±è¨ˆè³‡æ–™åº« API
    
    API æ–‡ä»¶ï¼šhttps://nstatdb.dgbas.gov.tw/dgbasAll/webMain.aspx?sys=100&funid=API
    """
    
    # ç”¢æ¥­ä»£ç¢¼å°æ‡‰è¡¨ï¼ˆéœ€è¦æ ¹æ“šå¯¦éš› API æ–‡ä»¶èª¿æ•´ï¼‰
    industry_codes = {
        "æ©Ÿæ¢°": "C29",
        "åŒ–å·¥": "C20",
        "é›»å­": "C26",
        "è³‡é€šè¨Š": "C26",
        "ç”ŸæŠ€": "C21",
        "æœå‹™æ¥­": "G-S"
    }
    
    # çµ±è¨ˆé¡å‹å°æ‡‰è¡¨
    stat_type_codes = {
        "ç”¢å€¼": "production",
        "å‡ºå£": "export",
        "å°±æ¥­äººæ•¸": "employment"
    }
    
    industry_code = industry_codes.get(industry)
    if not industry_code:
        return [TextContent(
            type="text",
            text=f"âŒ ä¸æ”¯æ´çš„ç”¢æ¥­åˆ¥ï¼š{industry}\n\næ”¯æ´çš„ç”¢æ¥­ï¼š{', '.join(industry_codes.keys())}"
        )]
    
    try:
        # å¯¦éš› API å‘¼å«
        async with httpx.AsyncClient(timeout=30.0) as client:
            # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš› API æ–‡ä»¶èª¿æ•´
            # ç›®å‰å…ˆå›å‚³èªªæ˜è¨Šæ¯
            
            result = f"""
## ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•æŸ¥è©¢çµæœ

**ç”¢æ¥­åˆ¥**ï¼š{industry}  
**çµ±è¨ˆé¡å‹**ï¼š{stat_type}  
**æŸ¥è©¢æœŸé–“**ï¼š{start_year} - {end_year}

---

âš ï¸ **API å¯¦ä½œèªªæ˜**ï¼š

ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•æä¾›ç¸½é«”çµ±è¨ˆè³‡æ–™åº« APIï¼Œä½†éœ€è¦ï¼š
1. æŸ¥è©¢ã€ŒåŠŸèƒ½ä»£ç¢¼ã€ï¼ˆæ¯å€‹çµ±è¨ˆè¡¨æœ‰å”¯ä¸€ä»£ç¢¼ï¼‰
2. åŠŸèƒ½ä»£ç¢¼åˆ—è¡¨ï¼šhttps://nstatdb.dgbas.gov.tw/

**å»ºè­°æ›¿ä»£æ–¹æ¡ˆ**ï¼š
ç”±æ–¼åŠŸèƒ½ä»£ç¢¼æŸ¥è©¢è¤‡é›œï¼Œå»ºè­°ä½¿ç”¨ Claude çš„ `search_web` å·¥å…·ï¼š

```
search_web("{industry} {stat_type} site:dgbas.gov.tw OR site:moea.gov.tw")
```

**API æŸ¥è©¢ç¯„ä¾‹**ï¼ˆéœ€è¦åŠŸèƒ½ä»£ç¢¼ï¼‰ï¼š
```
https://nstatdb.dgbas.gov.tw/dgbasAll/webMain.aspx?sys=100&funid=API
  ?function=[åŠŸèƒ½ä»£ç¢¼]
  &startTime={start_year}-01
  &endTime={end_year}-12
```

---

**ä¾†æº**ï¼š
- ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•ï¼šhttps://www.moea.gov.tw/Mns/dos/
- ç¸½é«”çµ±è¨ˆè³‡æ–™åº«ï¼šhttps://nstatdb.dgbas.gov.tw/
"""
            
            return [TextContent(type="text", text=result)]
            
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"âŒ æŸ¥è©¢å¤±æ•—ï¼š{str(e)}\n\nå»ºè­°ä½¿ç”¨ Claude çš„ search_web å·¥å…·ä½œç‚ºæ›¿ä»£æ–¹æ¡ˆã€‚"
        )]

# ============================================
# è¼”åŠ©åŠŸèƒ½ï¼šæœå°‹ç¶“æ¿Ÿéƒ¨ç¶²ç«™
# ============================================

async def search_moea_website(keyword: str) -> list[TextContent]:
    """æä¾›æœå°‹å»ºè­°ï¼ˆå¯¦éš›æœå°‹ç”± Claude çš„ search_web åŸ·è¡Œï¼‰"""
    
    result = f"""
## ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•æœå°‹å»ºè­°

**æœå°‹é—œéµå­—**ï¼š{keyword}

---

**å»ºè­°ä½¿ç”¨ Claude çš„ `search_web` å·¥å…·**ï¼š

```
search_web("{keyword} site:dgbas.gov.tw OR site:moea.gov.tw")
```

**æ¨è–¦æŸ¥è©¢ç¶²ç«™**ï¼š
- ç¶“æ¿Ÿéƒ¨çµ±è¨ˆè™•ï¼šhttps://www.moea.gov.tw/Mns/dos/
- ç¸½é«”çµ±è¨ˆè³‡æ–™åº«ï¼šhttps://nstatdb.dgbas.gov.tw/
- ç”¢æ¥­çµ±è¨ˆï¼šhttps://www.moea.gov.tw/Mns/dos/content/SubMenu.aspx?menu_id=6730

**æŸ¥è©¢æŠ€å·§**ï¼š
- åŠ ä¸Šå¹´ä»½ï¼š`{keyword} 2024`
- æŒ‡å®šçµ±è¨ˆé¡å‹ï¼š`{keyword} ç”¢å€¼` æˆ– `{keyword} å‡ºå£`
"""
    
    return [TextContent(type="text", text=result)]

# ============================================
# Server å•Ÿå‹•
# ============================================
# çŸ¥è­˜åº«æ›´æ–°åŠŸèƒ½
# ============================================

import subprocess

async def update_knowledge_base() -> list[TextContent]:
    """
    å¾ GitHub æ‹‰å–æœ€æ–°ç‰ˆæœ¬çš„çŸ¥è­˜åº«
    """
    try:
        # åŸ·è¡Œ git pull
        result = subprocess.run(
            ["git", "pull"],
            cwd=PROJECT_ROOT,
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode == 0:
            output = result.stdout.strip()
            if "Already up to date" in output or "å·²ç¶“æ˜¯æœ€æ–°" in output:
                return [TextContent(
                    type="text",
                    text="âœ… **çŸ¥è­˜åº«å·²æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼**\n\næ‚¨çš„ SBIR Skill çŸ¥è­˜åº«å·²ç¶“æ˜¯æœ€æ–°çš„äº†ï¼Œç„¡éœ€æ›´æ–°ã€‚"
                )]
            else:
                return [TextContent(
                    type="text",
                    text=f"âœ… **çŸ¥è­˜åº«æ›´æ–°æˆåŠŸï¼**\n\nå·²å¾ GitHub æ‹‰å–æœ€æ–°ç‰ˆæœ¬ã€‚\n\næ›´æ–°å…§å®¹ï¼š\n```\n{output}\n```\n\nè«‹é‡æ–°å•Ÿå‹• Claude Desktop ä»¥è¼‰å…¥æ–°å…§å®¹ã€‚"
                )]
        else:
            error_msg = result.stderr.strip() or result.stdout.strip()
            return [TextContent(
                type="text",
                text=f"âŒ **æ›´æ–°å¤±æ•—**\n\néŒ¯èª¤è¨Šæ¯ï¼š\n```\n{error_msg}\n```\n\nå¯èƒ½çš„åŸå› ï¼š\n1. æ²’æœ‰ç¶²è·¯é€£ç·š\n2. å°ˆæ¡ˆç›®éŒ„ä¸æ˜¯ç”¨ git clone ä¸‹è¼‰çš„\n3. æœ‰æœªæäº¤çš„æœ¬åœ°ä¿®æ”¹\n\næ‚¨å¯ä»¥æ‰‹å‹•åŸ·è¡Œï¼š\n```bash\ncd {PROJECT_ROOT} && git pull\n```"
            )]
            
    except subprocess.TimeoutExpired:
        return [TextContent(
            type="text",
            text="âŒ **æ›´æ–°è¶…æ™‚**\n\nç¶²è·¯é€£ç·šå¯èƒ½å¤ªæ…¢ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–æ‰‹å‹•åŸ·è¡Œï¼š\n```bash\ngit pull\n```"
        )]
    except FileNotFoundError:
        return [TextContent(
            type="text",
            text="âŒ **æ‰¾ä¸åˆ° Git**\n\næ‚¨çš„ç³»çµ±å¯èƒ½æ²’æœ‰å®‰è£ Gitï¼Œæˆ– Git ä¸åœ¨ç³»çµ±è·¯å¾‘ä¸­ã€‚\n\nè«‹æ‰‹å‹•ä¸‹è¼‰æœ€æ–°ç‰ˆæœ¬ï¼š\nhttps://github.com/backtrue/sbir-grants/archive/refs/heads/main.zip"
        )]
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"âŒ **æ›´æ–°å¤±æ•—**\n\nç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š{str(e)}\n\nè«‹æ‰‹å‹•åŸ·è¡Œï¼š\n```bash\ncd {PROJECT_ROOT} && git pull\n```"
        )]

# ============================================
# ç¶“è²»è©¦ç®—åŠŸèƒ½
# ============================================

async def calculate_budget(total_budget: float, phase: str = "phase1", project_type: str = "æŠ€è¡“ç ”ç™¼") -> list[TextContent]:
    """
    æ ¹æ“šè¨ˆç•«éšæ®µå’Œé¡å‹ï¼Œå»ºè­°ç¶“è²»åˆ†é…æ¯”ä¾‹
    """
    
    # é©—è­‰ç¶“è²»ç¯„åœ
    phase_limits = {
        "phase1": {"max": 150, "subsidy_max": 150, "name": "Phase 1"},
        "phase2": {"max": 2400, "subsidy_max": 1200, "name": "Phase 2"},
        "phase2plus": {"max": 1200, "subsidy_max": 600, "name": "Phase 2+"}
    }
    
    limit = phase_limits.get(phase, phase_limits["phase1"])
    
    if total_budget > limit["max"]:
        return [TextContent(
            type="text",
            text=f"âš ï¸ **ç¶“è²»è¶…éä¸Šé™**\n\n{limit['name']} è¨ˆç•«ç¸½ç¶“è²»ä¸Šé™ç‚º {limit['max']} è¬å…ƒï¼Œæ‚¨è¼¸å…¥çš„æ˜¯ {total_budget} è¬å…ƒ\n\nï¼ˆè£œåŠ©ä¸Šé™ï¼š{limit['subsidy_max']} è¬å…ƒï¼‰"
        )]
    
    # æ ¹æ“šè¨ˆç•«é¡å‹èª¿æ•´æ¯”ä¾‹
    allocation_templates = {
        "æŠ€è¡“ç ”ç™¼": {
            "äººäº‹è²»": {"ratio": 0.40, "desc": "ç ”ç™¼äººå“¡è–ªè³‡"},
            "æ¶ˆè€—æ€§å™¨æ": {"ratio": 0.20, "desc": "ææ–™ã€è©¦åŠ‘ã€é›¶çµ„ä»¶"},
            "è¨­å‚™è²»": {"ratio": 0.15, "desc": "ç ”ç™¼è¨­å‚™æ¡è³¼æˆ–ç§Ÿç”¨"},
            "å§”è¨—ç ”ç©¶è²»": {"ratio": 0.10, "desc": "å§”å¤–æ¸¬è©¦ã€èªè­‰"},
            "å·®æ—…è²»": {"ratio": 0.05, "desc": "æŠ€è¡“äº¤æµã€å®¢æˆ¶è¨ªè«‡"},
            "å°ˆåˆ©è²»": {"ratio": 0.03, "desc": "å°ˆåˆ©ç”³è«‹èˆ‡ç¶­è­·"},
            "ç®¡ç†è²»": {"ratio": 0.07, "desc": "è¡Œæ”¿ç®¡ç†è²»ç”¨"}
        },
        "è»Ÿé«”é–‹ç™¼": {
            "äººäº‹è²»": {"ratio": 0.55, "desc": "å·¥ç¨‹å¸«è–ªè³‡"},
            "æ¶ˆè€—æ€§å™¨æ": {"ratio": 0.05, "desc": "é–‹ç™¼å·¥å…·"},
            "é›²ç«¯æœå‹™è²»": {"ratio": 0.15, "desc": "é›²ç«¯ä¸»æ©Ÿã€API è²»ç”¨"},
            "å§”è¨—ç ”ç©¶è²»": {"ratio": 0.10, "desc": "å§”å¤–è¨­è¨ˆã€æ¸¬è©¦"},
            "å·®æ—…è²»": {"ratio": 0.05, "desc": "å®¢æˆ¶è¨ªè«‡ã€æŠ€è¡“äº¤æµ"},
            "å°ˆåˆ©è²»": {"ratio": 0.03, "desc": "è»Ÿé«”è‘—ä½œæ¬Š"},
            "ç®¡ç†è²»": {"ratio": 0.07, "desc": "è¡Œæ”¿ç®¡ç†è²»ç”¨"}
        },
        "ç¡¬é«”é–‹ç™¼": {
            "äººäº‹è²»": {"ratio": 0.35, "desc": "ç ”ç™¼äººå“¡è–ªè³‡"},
            "æ¶ˆè€—æ€§å™¨æ": {"ratio": 0.25, "desc": "é›»å­é›¶ä»¶ã€ææ–™"},
            "è¨­å‚™è²»": {"ratio": 0.20, "desc": "é‡æ¸¬è¨­å‚™ã€æ‰“æ¨£"},
            "å§”è¨—ç ”ç©¶è²»": {"ratio": 0.08, "desc": "å§”å¤–æ¸¬è©¦ã€èªè­‰"},
            "å·®æ—…è²»": {"ratio": 0.04, "desc": "ä¾›æ‡‰å•†æ‹œè¨ª"},
            "å°ˆåˆ©è²»": {"ratio": 0.03, "desc": "å°ˆåˆ©ç”³è«‹"},
            "ç®¡ç†è²»": {"ratio": 0.05, "desc": "è¡Œæ”¿ç®¡ç†è²»ç”¨"}
        },
        "æœå‹™å‰µæ–°": {
            "äººäº‹è²»": {"ratio": 0.50, "desc": "æœå‹™é–‹ç™¼äººå“¡"},
            "æ¶ˆè€—æ€§å™¨æ": {"ratio": 0.08, "desc": "æœå‹™æ‰€éœ€ææ–™"},
            "å ´åœ°è²»": {"ratio": 0.12, "desc": "æœå‹™å ´åŸŸç§Ÿç”¨"},
            "å§”è¨—ç ”ç©¶è²»": {"ratio": 0.12, "desc": "å¸‚å ´èª¿æŸ¥ã€é¡§å•"},
            "å·®æ—…è²»": {"ratio": 0.08, "desc": "å®¢æˆ¶è¨ªè«‡"},
            "è¡ŒéŠ·è²»": {"ratio": 0.05, "desc": "æ¨å»£æ´»å‹•"},
            "ç®¡ç†è²»": {"ratio": 0.05, "desc": "è¡Œæ”¿ç®¡ç†è²»ç”¨"}
        }
    }
    
    template = allocation_templates.get(project_type, allocation_templates["æŠ€è¡“ç ”ç™¼"])
    
    # è¨ˆç®—è£œåŠ©é‡‘é¡
    subsidy = min(total_budget * 0.5, limit["subsidy_max"])
    self_fund = total_budget - subsidy
    
    # ç”Ÿæˆç¶“è²»åˆ†é…è¡¨
    output = f"""# ğŸ’° SBIR ç¶“è²»è©¦ç®—çµæœ

## åŸºæœ¬è³‡è¨Š

| é …ç›® | é‡‘é¡ï¼ˆè¬å…ƒï¼‰ |
|------|-------------|
| è¨ˆç•«ç¸½ç¶“è²» | **{total_budget:,.0f}** |
| è£œåŠ©æ¬¾ï¼ˆ50%ï¼‰ | **{subsidy:,.0f}** |
| è‡ªç±Œæ¬¾ï¼ˆ50%ï¼‰ | **{self_fund:,.0f}** |

> è¨ˆç•«éšæ®µï¼š{limit['name']}
> è¨ˆç•«é¡å‹ï¼š{project_type}

---

## å»ºè­°ç¶“è²»åˆ†é…

| é …ç›® | æ¯”ä¾‹ | é‡‘é¡ï¼ˆè¬å…ƒï¼‰ | èªªæ˜ |
|------|------|-------------|------|
"""
    
    for item_name, item_data in template.items():
        amount = total_budget * item_data["ratio"]
        output += f"| {item_name} | {int(item_data['ratio']*100)}% | {amount:,.0f} | {item_data['desc']} |\n"
    
    output += f"""
---

## âš ï¸ æ³¨æ„äº‹é …

1. **äººäº‹è²»ä¸Šé™**ï¼šåŸå‰‡ä¸Šä¸è¶…éç¸½ç¶“è²» 50%
2. **ç®¡ç†è²»ä¸Šé™**ï¼šä¸è¶…éç¸½ç¶“è²» 10%
3. **è¨­å‚™è²»é™åˆ¶**ï¼šPhase 1 ç›¡é‡é¿å…å¤§å‹è¨­å‚™æ¡è³¼

## ğŸ“‹ ç¶“è²»ç·¨åˆ—å»ºè­°

"""
    
    # æ ¹æ“šè¨ˆç•«é¡å‹çµ¦äºˆå»ºè­°
    if project_type == "ç¡¬é«”é–‹ç™¼":
        output += """- è¨­å‚™è²»éœ€èªªæ˜å¿…è¦æ€§ï¼Œå„ªå…ˆè€ƒæ…®ç§Ÿç”¨
- æ‰“æ¨£è²»ç”¨ç´å…¥ã€Œæ¶ˆè€—æ€§å™¨æã€
- èªè­‰æ¸¬è©¦åˆ—å…¥ã€Œå§”è¨—ç ”ç©¶è²»ã€
"""
    elif project_type == "è»Ÿé«”é–‹ç™¼":
        output += """- é›²ç«¯æœå‹™è²»éœ€æä¾›ä¼°ç®—ä¾æ“š
- è»Ÿé«”æˆæ¬Šè²»å¯ç´å…¥ã€Œæ¶ˆè€—æ€§å™¨æã€
- äººäº‹è²»æ¯”ä¾‹è¼ƒé«˜æ˜¯æ­£å¸¸çš„
"""
    elif project_type == "æœå‹™å‰µæ–°":
        output += """- å ´åœ°è²»éœ€èˆ‡æœå‹™å…§å®¹ç›¸é—œ
- å¸‚å ´èª¿æŸ¥å¯åˆ—å…¥ã€Œå§”è¨—ç ”ç©¶è²»ã€
- å¯ç·¨åˆ—å°‘é‡è¡ŒéŠ·æ¨å»£è²»ç”¨
"""
    else:
        output += """- å„é …è²»ç”¨éœ€é™„æ¡è³¼è¦åŠƒèªªæ˜
- å§”å¤–é …ç›®éœ€èªªæ˜å¿…è¦æ€§
- å·®æ—…è²»éœ€åˆ—æ˜ç›®çš„åœ°å’Œç›®çš„
"""
    
    output += """
---

> âš ï¸ æ­¤ç‚ºå»ºè­°åˆ†é…ï¼Œå¯¦éš›ç·¨åˆ—è«‹ä¾è¨ˆç•«éœ€æ±‚èª¿æ•´
> ğŸ“– è©³ç´°èªªæ˜è«‹åƒè€ƒï¼šç¶“è²»ç·¨åˆ—æŒ‡å—
"""
    
    return [TextContent(type="text", text=output)]

# ============================================
# Word åŒ¯å‡ºåŠŸèƒ½
# ============================================

from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
import re

async def export_proposal_word(
    content: str,
    filename: str = "SBIR_è¨ˆç•«æ›¸",
    company_name: str = "",
    project_name: str = ""
) -> list[TextContent]:
    """
    å°‡è¨ˆç•«æ›¸ Markdown å…§å®¹åŒ¯å‡ºç‚º Word æª”æ¡ˆ
    """
    try:
        # å»ºç«‹ Word æ–‡ä»¶
        doc = Document()
        
        # è¨­å®šé è¨­å­—å‹
        style = doc.styles['Normal']
        style.font.name = 'æ¨™æ¥·é«”'
        style.font.size = Pt(12)
        
        # æ¨™é¡Œé 
        if project_name:
            title = doc.add_paragraph()
            title.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = title.add_run(project_name)
            run.font.size = Pt(24)
            run.font.bold = True
            doc.add_paragraph()  # ç©ºè¡Œ
        
        if company_name:
            company = doc.add_paragraph()
            company.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = company.add_run(company_name)
            run.font.size = Pt(16)
            doc.add_paragraph()  # ç©ºè¡Œ
        
        # åˆ†é 
        if project_name or company_name:
            doc.add_page_break()
        
        # è§£æ Markdown ä¸¦è½‰æ›ç‚º Word
        lines = content.split('\n')
        in_code_block = False
        
        for line in lines:
            # è™•ç†ç¨‹å¼ç¢¼å€å¡Š
            if line.startswith('```'):
                in_code_block = not in_code_block
                continue
            
            if in_code_block:
                p = doc.add_paragraph(line)
                p.style = 'Normal'
                p.paragraph_format.left_indent = Inches(0.5)
                continue
            
            # è™•ç†æ¨™é¡Œ
            if line.startswith('# '):
                p = doc.add_paragraph(line[2:])
                run = p.runs[0]
                run.font.size = Pt(18)
                run.font.bold = True
                run.font.color.rgb = RGBColor(0, 0, 128)
            elif line.startswith('## '):
                p = doc.add_paragraph(line[3:])
                run = p.runs[0]
                run.font.size = Pt(16)
                run.font.bold = True
                run.font.color.rgb = RGBColor(0, 0, 128)
            elif line.startswith('### '):
                p = doc.add_paragraph(line[4:])
                run = p.runs[0]
                run.font.size = Pt(14)
                run.font.bold = True
            
            # è™•ç†åˆ—è¡¨
            elif line.startswith('- ') or line.startswith('* '):
                p = doc.add_paragraph(line[2:], style='List Bullet')
            elif re.match(r'^\d+\. ', line):
                text = re.sub(r'^\d+\. ', '', line)
                p = doc.add_paragraph(text, style='List Number')
            
            # è™•ç†åˆ†éš”ç·š
            elif line.strip() == '---':
                doc.add_paragraph('_' * 50)
            
            # è™•ç†ç©ºè¡Œ
            elif line.strip() == '':
                doc.add_paragraph()
            
            # ä¸€èˆ¬æ®µè½
            else:
                # è™•ç†ç²—é«” **text**
                if '**' in line:
                    p = doc.add_paragraph()
                    parts = re.split(r'(\*\*.*?\*\*)', line)
                    for part in parts:
                        if part.startswith('**') and part.endswith('**'):
                            run = p.add_run(part[2:-2])
                            run.bold = True
                        else:
                            p.add_run(part)
                else:
                    doc.add_paragraph(line)
        
        # å„²å­˜æª”æ¡ˆ
        output_dir = os.path.expanduser("~/Documents")
        output_path = os.path.join(output_dir, f"{filename}.docx")
        doc.save(output_path)
        
        return [TextContent(
            type="text",
            text=f"""âœ… **Word æª”æ¡ˆå·²æˆåŠŸåŒ¯å‡ºï¼**

ğŸ“„ æª”æ¡ˆä½ç½®ï¼š`{output_path}`

æ‚¨å¯ä»¥ï¼š
1. é–‹å•Ÿæª”æ¡ˆæª¢è¦–å…§å®¹
2. æ ¹æ“šéœ€æ±‚èª¿æ•´æ ¼å¼
3. ç›´æ¥ç”¨æ–¼ SBIR ç”³è«‹é€ä»¶

> ğŸ’¡ æç¤ºï¼šå»ºè­°é–‹å•Ÿå¾Œæª¢æŸ¥æ ¼å¼ï¼Œä¸¦è£œå……åœ–è¡¨ç­‰è¦–è¦ºå…ƒç´ 
"""
        )]
        
    except Exception as e:
        return [TextContent(
            type="text",
            text=f"âŒ **åŒ¯å‡ºå¤±æ•—**\n\néŒ¯èª¤è¨Šæ¯ï¼š{str(e)}\n\nè«‹ç¢ºèªï¼š\n1. å·²å®‰è£ python-docx\n2. æœ‰å¯«å…¥æ¬Šé™åˆ° ~/Documents"
        )]

# ============================================
# è¨ˆç•«æ›¸å®Œæ•´åº¦æª¢æ ¸åŠŸèƒ½
# ============================================

async def check_proposal(proposal_content: str, phase: str = "phase1") -> list[TextContent]:
    """
    æª¢æ ¸ SBIR è¨ˆç•«æ›¸å®Œæ•´åº¦
    é€™æ˜¯ã€Œè‡ªæˆ‘æª¢æŸ¥å·¥å…·ã€ï¼Œä¸æ˜¯ã€Œè©•å¯©çµæœé æ¸¬ã€
    """
    
    # å®šç¾© Phase 1 æª¢æ ¸é …ç›®
    phase1_checks = [
        {
            "category": "åŸºæœ¬è³‡è¨Š",
            "items": [
                {"name": "å…¬å¸åç¨±", "keywords": ["å…¬å¸", "è‚¡ä»½æœ‰é™", "æœ‰é™å…¬å¸"]},
                {"name": "è¨ˆç•«åç¨±", "keywords": ["è¨ˆç•«åç¨±", "è¨ˆç•«é¡Œç›®"]},
                {"name": "è¨ˆç•«æœŸç¨‹", "keywords": ["æœŸç¨‹", "æœˆ", "å¹´"]},
            ]
        },
        {
            "category": "å•é¡Œé™³è¿°",
            "items": [
                {"name": "ç”¢æ¥­ç—›é»æè¿°", "keywords": ["ç—›é»", "å•é¡Œ", "æŒ‘æˆ°", "å›°é›£", "éœ€æ±‚"]},
                {"name": "ç¾æ³èªªæ˜", "keywords": ["ç¾æ³", "ç›®å‰", "ç¾æœ‰", "å‚³çµ±"]},
                {"name": "å•é¡Œé‡åŒ–æ•¸æ“š", "keywords": ["å„„", "è¬", "%", "æ¯”ä¾‹", "çµ±è¨ˆ"]},
            ]
        },
        {
            "category": "å‰µæ–°å…§å®¹",
            "items": [
                {"name": "å‰µæ–°é»æè¿°", "keywords": ["å‰µæ–°", "çªç ´", "ç¨å‰µ", "é¦–å‰µ", "åŸå‰µ"]},
                {"name": "èˆ‡ç¾æœ‰æŠ€è¡“å·®ç•°", "keywords": ["å·®ç•°", "ä¸åŒ", "å„ªæ–¼", "ç›¸è¼ƒ", "æ¯”è¼ƒ"]},
                {"name": "æŠ€è¡“å„ªå‹¢èªªæ˜", "keywords": ["å„ªå‹¢", "å„ªé»", "ç‰¹è‰²", "é ˜å…ˆ"]},
            ]
        },
        {
            "category": "å¸‚å ´åˆ†æ",
            "items": [
                {"name": "ç›®æ¨™å¸‚å ´æè¿°", "keywords": ["ç›®æ¨™å¸‚å ´", "å®¢æˆ¶", "TA", "ä½¿ç”¨è€…"]},
                {"name": "å¸‚å ´è¦æ¨¡ï¼ˆTAM/SAM/SOMï¼‰", "keywords": ["TAM", "SAM", "SOM", "å¸‚å ´è¦æ¨¡", "ç”¢å€¼"]},
                {"name": "å•†æ¥­æ¨¡å¼", "keywords": ["å•†æ¥­æ¨¡å¼", "ç²åˆ©", "ç‡Ÿæ”¶", "æ”¶è²»"]},
            ]
        },
        {
            "category": "æŠ€è¡“å¯è¡Œæ€§",
            "items": [
                {"name": "æŠ€è¡“æ–¹æ¡ˆèªªæ˜", "keywords": ["æŠ€è¡“", "æ–¹æ³•", "æ¶æ§‹", "ç³»çµ±"]},
                {"name": "å‰æœŸé©—è­‰æˆæœ", "keywords": ["é©—è­‰", "æ¸¬è©¦", "å¯¦é©—", "å‰æœŸ", "é››å‹"]},
                {"name": "é¢¨éšªè©•ä¼°", "keywords": ["é¢¨éšª", "æŒ‘æˆ°", "å›°é›£"]},
            ]
        },
        {
            "category": "åœ˜éšŠä»‹ç´¹",
            "items": [
                {"name": "åœ˜éšŠæˆå“¡", "keywords": ["åœ˜éšŠ", "æˆå“¡", "äººå“¡"]},
                {"name": "ç›¸é—œç¶“é©—", "keywords": ["ç¶“é©—", "ç¶“æ­·", "èƒŒæ™¯", "å°ˆé•·"]},
                {"name": "åˆ†å·¥è¦åŠƒ", "keywords": ["åˆ†å·¥", "è² è²¬", "è·è²¬"]},
            ]
        },
        {
            "category": "åŸ·è¡Œè¨ˆç•«",
            "items": [
                {"name": "å·¥ä½œé …ç›®", "keywords": ["å·¥ä½œ", "é …ç›®", "ä»»å‹™"]},
                {"name": "æ™‚ç¨‹è¦åŠƒ", "keywords": ["æ™‚ç¨‹", "é€²åº¦", "ç”˜ç‰¹", "æœˆ"]},
                {"name": "æŸ¥æ ¸é»", "keywords": ["æŸ¥æ ¸", "é‡Œç¨‹ç¢‘", "KPI", "æŒ‡æ¨™"]},
            ]
        },
        {
            "category": "ç¶“è²»è¦åŠƒ",
            "items": [
                {"name": "äººäº‹è²»", "keywords": ["äººäº‹è²»", "è–ªè³‡", "äººåŠ›"]},
                {"name": "ææ–™è²»/è¨­å‚™è²»", "keywords": ["ææ–™", "è¨­å‚™", "å™¨æ", "è€—æ"]},
                {"name": "å…¶ä»–è²»ç”¨", "keywords": ["å§”è¨—", "å·®æ—…", "ç®¡ç†è²»"]},
            ]
        },
    ]
    
    # åŸ·è¡Œæª¢æ ¸
    content_lower = proposal_content.lower()
    results = []
    total_items = 0
    passed_items = 0
    
    for category in phase1_checks:
        category_results = {
            "name": category["category"],
            "items": []
        }
        
        for item in category["items"]:
            total_items += 1
            # æª¢æŸ¥æ˜¯å¦åŒ…å«é—œéµå­—
            found = any(keyword in proposal_content for keyword in item["keywords"])
            if found:
                passed_items += 1
                status = "âœ…"
            else:
                status = "âŒ"
            
            category_results["items"].append({
                "name": item["name"],
                "status": status,
                "found": found
            })
        
        results.append(category_results)
    
    # æ ¼å¼åŒ–è¼¸å‡º
    output = f"""# ğŸ“‹ SBIR è¨ˆç•«æ›¸å®Œæ•´åº¦æª¢æ ¸

> âš ï¸ **é‡è¦æé†’**ï¼šé€™æ˜¯ã€Œè‡ªæˆ‘æª¢æŸ¥å·¥å…·ã€ï¼Œç”¨ä¾†ç¢ºèªè¨ˆç•«æ›¸æ˜¯å¦æ¶µè“‹å¿…è¦å…§å®¹ã€‚  
> æª¢æ ¸çµæœ **ä¸ä»£è¡¨å¯©æŸ¥çµæœé æ¸¬**ï¼Œæœ€çµ‚é€šéèˆ‡å¦å–æ±ºæ–¼å¯©æŸ¥å§”å“¡è©•ä¼°ã€‚

---

## æª¢æ ¸çµæœæ‘˜è¦

**å®Œæ•´åº¦**ï¼š{passed_items}/{total_items} é …ç›®å·²æ¶µè“‹ï¼ˆ{int(passed_items/total_items*100)}%ï¼‰

"""
    
    for category in results:
        category_passed = sum(1 for item in category["items"] if item["found"])
        category_total = len(category["items"])
        
        if category_passed == category_total:
            category_status = "âœ…"
        elif category_passed == 0:
            category_status = "âŒ"
        else:
            category_status = "âš ï¸"
        
        output += f"### {category_status} {category['name']} ({category_passed}/{category_total})\n\n"
        
        for item in category["items"]:
            output += f"- {item['status']} {item['name']}\n"
        
        output += "\n"
    
    # æ·»åŠ å»ºè­°
    missing_items = [
        f"- {item['name']}"
        for category in results
        for item in category["items"]
        if not item["found"]
    ]
    
    if missing_items:
        output += f"""---

## ğŸ’¡ å»ºè­°è£œå¼·é …ç›®

ä»¥ä¸‹é …ç›®å¯èƒ½éœ€è¦è£œå……æˆ–åŠ å¼·ï¼š

"""
        for item in missing_items[:10]:  # æœ€å¤šé¡¯ç¤º 10 é …
            output += f"{item}\n"
        
        if len(missing_items) > 10:
            output += f"\nï¼ˆé‚„æœ‰ {len(missing_items) - 10} é …æœªåˆ—å‡ºï¼‰\n"
    else:
        output += """---

## ğŸ‰ æ­å–œï¼

æ‚¨çš„è¨ˆç•«æ›¸æ¶µè“‹äº†æ‰€æœ‰å¿…è¦é …ç›®ã€‚å»ºè­°é€²ä¸€æ­¥å„ªåŒ–ï¼š
- ç¢ºèªå„é …å…§å®¹çš„æ·±åº¦å’Œå…·é«”æ€§
- è£œå……é‡åŒ–æ•¸æ“šå’Œä½è­‰è³‡æ–™
- è«‹ä»–äººå¯©é–±ä¸¦çµ¦äºˆå›é¥‹
"""
    
    output += """
---

ğŸ“– éœ€è¦æ›´å¤šæŒ‡å¼•ï¼Ÿè«‹èªªã€Œæœå°‹ [é—œéµå­—]ã€æŸ¥è©¢çŸ¥è­˜åº«
"""
    
    return [TextContent(type="text", text=output)]

# ============================================
# ä¸»ç¨‹å¼å…¥å£
# ============================================

async def main():
    """å•Ÿå‹• MCP Server"""
    from mcp.server.stdio import stdio_server
    
    async with stdio_server() as (read_stream, write_stream):
        await app.run(
            read_stream,
            write_stream,
            app.create_initialization_options()
        )

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())

